{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCOS_TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.,   4.],\n",
       "        [ 12.,   4.],\n",
       "        [ 20.,   4.],\n",
       "        ...,\n",
       "        [364., 380.],\n",
       "        [372., 380.],\n",
       "        [380., 380.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_locations(features, strides, dense_points=1):\n",
    "    locations = []\n",
    "    for level, feature in enumerate(features):\n",
    "        h, w = feature.size()[-2:]\n",
    "        locations_per_lever = compute_locations_per_lever(h, w, strides[level], feature.device, dense_points)\n",
    "        locations.append(locations_per_lever)\n",
    "    return locations\n",
    "\n",
    "def compute_locations_per_lever(h, w, stride, device, dense_points=1):\n",
    "    shifts_x = torch.arange(0, w * stride, step=stride, dtype=torch.float32, device=device)\n",
    "    shifts_y = torch.arange(0, h * stride, step=stride, dtype=torch.float32, device=device)\n",
    "    shift_y, shift_x = torch.meshgrid((shifts_y, shifts_x))\n",
    "    shift_x = shift_x.reshape(-1)\n",
    "    shift_y = shift_y.reshape(-1)\n",
    "    locations = torch.stack((shift_x, shift_y), dim=1) + stride // 2\n",
    "    #locations = get_dense_locations(locations, stride, dense_points, device)\n",
    "    return locations\n",
    "\n",
    "h = [48]\n",
    "w = [48]\n",
    "stride = []\n",
    "features = torch.rand(2, 128, 48, 48)\n",
    "strides = [8, 16, 22]\n",
    "compute_locations_per_lever(48, 48, 8, device=features.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loc1 = torch.rand(6, 2)\n",
    "loc2 = torch.rand(4, 2)\n",
    "locations = torch.cat([loc1, loc2], dim=0)\n",
    "print(locations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.,  64.],\n",
       "        [ -1.,  64.],\n",
       "        [ -1.,  64.],\n",
       "        [ -1.,  64.],\n",
       "        [ -1.,  64.],\n",
       "        [ -1.,  64.],\n",
       "        [ 64., 128.],\n",
       "        [ 64., 128.],\n",
       "        [ 64., 128.],\n",
       "        [ 64., 128.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loc_ranges = [[-1, 64], [64, 128]]\n",
    "expanded_loc_ranges = []\n",
    "locations = [loc1, loc2]\n",
    "for i in range(len(locations)):\n",
    "    expanded_loc_ranges.append(locations[i].new_tensor(loc_ranges[i])[None].expand(len(locations[i]), -1))\n",
    "expanded_loc_ranges\n",
    "loc_ranges = torch.cat(expanded_loc_ranges, dim=0)\n",
    "loc_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 64., 128.],\n",
       "        [ 64., 128.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc1.new_tensor([64, 128])[None].expand(2, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fcos_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = torch.rand(2,4)\n",
    "points = torch.randn(4, 2)\n",
    "xs = points[:, 1]\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_xs = xs[:, None].expand(4, 6)\n",
    "gt_xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4014,  0.3728],\n",
       "         [ 0.5106, -0.2264],\n",
       "         [ 1.0799, -0.5658],\n",
       "         [-0.3043, -0.4544]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape\n",
    "points[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fckp_match(\n",
    "        points,    #(K, 2)\n",
    "        gt,        #(n, 8)\n",
    "        loc_ranges,#(25, 2)\n",
    "        num_points_per,#[5] W*H\n",
    "        cfg,\n",
    "        strides=[8, 16, 32, 64, 128],\n",
    "        ig=None):\n",
    "    #一张图上所有的点匹配gt\n",
    "    INF = 1e10\n",
    "    num_gts = gt.shape[0]\n",
    "    K = points.shape[0]\n",
    "    gt_labels = gt[:, 4]\n",
    "    xs, ys = points[:, 0], points[:, 1]\n",
    "    gt_bboxes = gt[:, :4]\n",
    "    areas = (gt_bboxes[:, 2] - gt_bboxes[:, 0] + 1) * (gt_bboxes[:, 3] - gt_bboxes[:, 1] + 1)\n",
    "\n",
    "    areas = areas[None].repeat(K, 1)\n",
    "    loc_ranges = loc_ranges[:, None, :].expand(K, num_gts, 2)\n",
    "    gt_bboxes = gt_bboxes[None].expand(K, num_gts, 4)\n",
    "    gt_xs = xs[:, None].expand(K, num_gts)\n",
    "    gt_ys = ys[:, None].expand(K, num_gts) #扩展到某一维(直接重复)(K)-->(k, num_gts)\n",
    "\n",
    "    left = gt_xs - gt_bboxes[..., 0]\n",
    "    right = gt_bboxes[..., 2] - gt_xs\n",
    "    top = gt_ys - gt_bboxes[..., 1]\n",
    "    bottom = gt_bboxes[..., 3] - gt_ys\n",
    "    bbox_targets = torch.stack((left, top, right, bottom), -1)\n",
    "\n",
    "    if cfg.get('center_sample', False):\n",
    "        sample_mask = get_sample_region(gt_bboxes, strides, num_points_per, gt_xs, gt_ys, radius=cfg.get('pos_radius', 1)) # noqa E501\n",
    "    else:\n",
    "        sample_mask = bbox_targets.min(-1)[0] > 0\n",
    "\n",
    "    max_loc_distance = bbox_targets.max(-1)[0]\n",
    "    inside_loc_range = (max_loc_distance >= loc_ranges[..., 0]) & (max_loc_distance <= loc_ranges[..., 1])\n",
    "\n",
    "    # if there are still more than one objects for a location,\n",
    "    # we choose the one with minimal area\n",
    "    areas[sample_mask == 0] = INF\n",
    "\n",
    "    areas[inside_loc_range == 0] = INF\n",
    "    min_area, min_area_inds = areas.min(dim=1)\n",
    "    labels = gt_labels[min_area_inds]\n",
    "    labels[min_area == INF] = 0\n",
    "    bbox_targets = bbox_targets[range(K), min_area_inds]\n",
    "\n",
    "    return labels, bbox_targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
